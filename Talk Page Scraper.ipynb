{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikichatter as wc\n",
    "import mwapi\n",
    "import requests\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When working with mwapi, you should begin your file with a session, with a user_agent\n",
    "#this allows you to make multiple calls without getting shut out of the api\n",
    "\n",
    "session = mwapi.Session('https://en.wikipedia.org', user_agent='ewhit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Creating a query\n",
    ">params holds the parameters you want to use when calling mwapi. This makes it easy to  \n",
    "manipulate each parameter, particularly \"titles\" Here, we can see that titles  \n",
    "has been set to [\"Wikipedia:List of controversial issues\"](https://en.wikipedia.org/wiki/Wikipedia:List_of_controversial_issues) \n",
    "These parameters will do the following:\n",
    "    >>Tell mwapi to make a query (action), to get all of the links present (prop) on the page \n",
    "    >>\"Wikipedia:List of controversial issues\" (titles), and to return this in json format (format)\n",
    ">The query will end up looking like this:  \n",
    "    >>[https://en.wikipedia.org/w/api.php?action=query&prop=links&titles=Wikipedia:List%20of%20controversial%20issues&pllimit=max](https://en.wikipedia.org/w/api.php?action=query&prop=links&titles=Wikipedia:List%20of%20controversial%20issues&pllimit=max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def params():\n",
    "    return{\n",
    "    \"action\": \"query\",\n",
    "    \"titles\" : \"Wikipedia:List of controversial issues\",\n",
    "    \"prop\": \"links\",\n",
    "    \"format\": \"json\",\n",
    "    \"pllimit\" : \"1\"\n",
    "    }\n",
    "\n",
    "\n",
    "#kwargs calls params in order to be set - this is what you will end up passing\n",
    "kwargs=params()\n",
    "\n",
    "#This holds the results of your query, and continuation=True tells session.get to keep going when it reaches the\n",
    "#limit (of 50, I believe), so that you can get *all* of the links on the page\n",
    "#Because we wanted all the titles on the page, query will be a generator\n",
    "query = session.get(**kwargs, continuation = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end for loop\n"
     ]
    }
   ],
   "source": [
    "#Pagelist is a list that will ultimately hold the titles of all the controversial pages\n",
    "pageList = []\n",
    "\n",
    "#This loops through all the results of the earlier query\n",
    "#However, because what we want to do next is acquire the talk page for each controversial\n",
    "#page, we will need to do a bit of trimming\n",
    "#Ultimately, this bit of code will put \"Talk:page title\" into our list of pages to visit later\n",
    "for request in query:\n",
    "    title = json.dumps(request)\n",
    "    index = title.find('links')\n",
    "    temp = title[index:]\n",
    "    index2 = temp.find('title')\n",
    "    temp2 = temp[index2:]\n",
    "    temp3 = temp2[9:]\n",
    "    index3 = temp3.find('\"')\n",
    "    temp4 = temp3[:index3]\n",
    "    toTalk = \"Talk:\"\n",
    "    temp5 = toTalk + temp4\n",
    "    pageList.append(temp5)\n",
    "    \n",
    "\n",
    "print(\"end for loop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Queries\n",
    "> Each query will return something like this: \n",
    ">> {\"query\": {\"pages\": {\"27985631\": {\"links\": [{\"ns\": 0, \"title\": \"1919 World Series\"}], \"ns\": 4, \"title\": \"Wikipedia:List of controversial issues\", \"pageid\": 27985631}}}, \"continue\": {\"plcontinue\": \"27985631|0|1953_Iranian_coup_d'\\u00e9tat\", \"continue\": \"||\"}}  \n",
    "\n",
    ">Because we want to query each individual talk page, we will need to parse the title of the talk page from what each query returns, which is what the above code does. After this loop has run, we should have a list of things that look like \"Talk:1919 World Series\" \n",
    "\n",
    ">After parsing and setting the param to the appropriate parameters, a query that looks like this should be generated:  \n",
    ">>[https://en.wikipedia.org/w/api.php?action=query&prop=revisions&rvprop=content&titles=Talk:1919%20World%20Series&format=json](https://en.wikipedia.org/w/api.php?action=query&prop=revisions&rvprop=content&titles=Talk:1919%20World%20Series&format=json)  \n",
    ">This will get the content of the page queried  \n",
    ">This content is then passed to wc.parse so that it can be parsed - it looks quite unreadable initially  \n",
    ">This appears to be where errors are happening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a dictionary to hold the talk page title, and the content of that talk page\n",
    "content = {}\n",
    "\n",
    "#This loops through each page in our list of controversial talk pages\n",
    "for page in pageList:\n",
    "    \n",
    "    #Once again, we want to define the parameters we will send to session.get\n",
    "    #Here, we are again querying, and \"titles\" : page will query the page with the corresponding title\n",
    "    #(which is why we just stored the talk page titles earlier)\n",
    "    #\"prop\" : \"revisions\" gets the most recent revision, and \"rvprop\" : \"content\" gets the current content\n",
    "    def param(page):\n",
    "        return{\n",
    "        \"action\": \"query\",\n",
    "        \"titles\" : page,\n",
    "        \"prop\" : \"revisions\",\n",
    "        \"rvprop\" : \"content\",\n",
    "        \"format\": \"json\",\n",
    "        }\n",
    "    \n",
    "    #Here we again set kwargs to send to session.get\n",
    "    kwargs2 = param(page)\n",
    "    query = session.get(**kwargs2, continuation=True )\n",
    "    \n",
    "    #Because this portion of code was throwing errors, I have used several try-catch blocks\n",
    "        #Several were used because the first kind returned a TypeError, so I caught that as well\n",
    "    #try-catch block\n",
    "    i = 0\n",
    "    for request in query:\n",
    "        #This is the text that results from the individual query (so, the talk page content)\n",
    "        text = json.dumps(request)\n",
    "\n",
    "        try:\n",
    "            #Here, we try to parse the talk page content\n",
    "            try:\n",
    "                parsed_text = wc.parse(text)\n",
    "            except NameError:\n",
    "                i = i + 1  \n",
    "            except NoUsernameError(parsed_text):\n",
    "                i = i + 1\n",
    "        except TypeError:\n",
    "            i = i + 1\n",
    "\n",
    "        #Here, we add an entry to the dictionary of the current page's title and parsed text\n",
    "        content[page] = parsed_text\n",
    "            \n",
    "print(\"finished querrying\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This simply prints the page titles and their corresponding cleaned text to a file\n",
    "#with open(\"parsedTalkPages.csv\", \"w\", newline = '') as w:\n",
    "    #writer = csv.writer(w, delimiter = ',')\n",
    "    #for key, value in content.items():\n",
    "     #   writer.writerow([key, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
